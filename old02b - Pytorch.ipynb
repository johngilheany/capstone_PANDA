{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c11a3d-7f08-4a1d-ab1c-771cb09917c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot inherit non-frozen dataclass from a frozen one",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet50, ResNet50_Weights\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\ops\\roi_align.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, register_backend\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replay\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckFunctionManager, GuardedCode\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputGraph\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExecutionRecord\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py:23\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     Checkpointable,\n\u001b[0;32m     16\u001b[0m     Guard,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     TracingContext,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShapeEnv\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging, variables\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompiledFn, CompilerFn\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_instruction, Instruction, unique_id\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\variables\\base.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variables\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unimplemented\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrSource, Source\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_values, identity, istype, odict_values\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMutableLocal\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_dynamo\\source.py:48\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_input_source\u001b[39m(source):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m source\u001b[38;5;241m.\u001b[39mguard_source() \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m     41\u001b[0m         GuardSource\u001b[38;5;241m.\u001b[39mLOCAL,\n\u001b[0;32m     42\u001b[0m         GuardSource\u001b[38;5;241m.\u001b[39mGLOBAL,\n\u001b[0;32m     43\u001b[0m         GuardSource\u001b[38;5;241m.\u001b[39mLOCAL_NN_MODULE,\n\u001b[0;32m     44\u001b[0m         GuardSource\u001b[38;5;241m.\u001b[39mGLOBAL_NN_MODULE,\n\u001b[0;32m     45\u001b[0m     ]\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;129m@dataclasses\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLocalSource\u001b[39;00m(Source):\n\u001b[0;32m     50\u001b[0m     local_name: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, codegen):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\dataclasses.py:1230\u001b[0m, in \u001b[0;36mdataclass\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\dataclasses.py:1220\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m-> 1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _process_class(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;28mrepr\u001b[39m, eq, order, unsafe_hash,\n\u001b[0;32m   1221\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[0;32m   1222\u001b[0m                           weakref_slot)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\dataclasses.py:988\u001b[0m, in \u001b[0;36m_process_class\u001b[1;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_dataclass_bases:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# Raise an exception if any of our bases are frozen, but we're not.\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m any_frozen_base \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m frozen:\n\u001b[1;32m--> 988\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot inherit non-frozen dataclass from a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    989\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrozen one\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# Raise an exception if we're frozen, but none of our bases are.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_frozen_base \u001b[38;5;129;01mand\u001b[39;00m frozen:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot inherit non-frozen dataclass from a frozen one"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm\n",
    "import zipfile\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6c22d-a055-4d19-a145-8a75daefc0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_tile_images(N_cancer, N_noncancer, path):\n",
    "    cancer_imgs = glob.glob(os.path.join(path, '*_cancer.png')) # select all file paths of images containing cancer\n",
    "    noncancer_imgs = glob.glob(os.path.join(path, '*_noncancer.png')) # same for images not containing any cancer\n",
    "    tiles = random.sample(cancer_imgs, N_cancer) + random.sample(noncancer_imgs, N_noncancer) # sample N_cancer and N_noncancer file paths from the two lists above\n",
    "    labels = np.concatenate((np.ones(N_cancer), np.zeros(N_noncancer))) # label as 1 for cancer and 0 for non-cancer\n",
    "    indices = list(range(N_cancer + N_noncancer)) \n",
    "    random.shuffle(indices) # random list of indices to shuffle the list containing cancer and non-cancer file paths\n",
    "    return [tiles[i] for i in indices], labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8dc42-bc3b-4714-8e4e-dd8f3bfed98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"data/tiled_images/output/\" # path to the folder containing the imgs\n",
    "\n",
    "cancer_imgs = glob.glob(os.path.join(path, '*_cancer.png')) # select all file paths of images containing cancer\n",
    "noncancer_imgs = glob.glob(os.path.join(path, '*_noncancer.png')) # same for images not containing any cancer\n",
    "# len(cancer_imgs)\n",
    "# len(noncancer_imgs)\n",
    "\n",
    "N_cancer = 100 # number of imgs with cancer\n",
    "N_noncancer = 100 # number of imgs without cancer\n",
    "\n",
    "# Display some random images to observe the features of cancer vs non-cancer cells\n",
    "tiles, labels = sample_tile_images(N_cancer, N_noncancer, path) # get list of train images\n",
    "label_dict = {1: 'cancer', 0: 'non-cancer'} # dictionary of labels\n",
    "# j = random.randint(0, len(labels)) # pick a random image\n",
    "j = 0 # pick a random image\n",
    "im_frame = Image.open(tiles[j])\n",
    "np_frame = np.array(im_frame)\n",
    "plt.imshow(np_frame)\n",
    "print(label_dict[labels[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e7fc7-8f78-4fdf-8939-cdb671957b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(net, dataloader, criterion, optimizer, epochs=5):\n",
    "    i = 0\n",
    "    run_loss = 0\n",
    "    # print start\n",
    "    print('Start of training')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch:', epoch)\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            run_loss += loss.item()\n",
    "        # print statistics\n",
    "        print('Loss:', run_loss, '\\n')\n",
    "        run_loss = 0.0\n",
    "        \n",
    "    return net\n",
    "\n",
    "pxsize = 227 # size of the images to be used by the network, can be center-cropped below 256\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(pxsize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae62a64-b612-43cf-bb8e-4141df8ab665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split and prepare data for training\n",
    "train_fraction = 0.7 # fraction of train samples\n",
    "pxsize = 227 # size of the images to be used by the network, can be center-cropped below 256\n",
    "random.seed(123)\n",
    "\n",
    "tiles, labels = sample_tile_images(N_cancer, N_noncancer, path) # get list of train images\n",
    "data = preprocess(Image.open(tiles[0]).convert('RGB')).reshape(1,3,pxsize,pxsize) # convert to RGB to drop alpha (transparency) channel of png \n",
    "\n",
    "for tile in tiles[1:]:\n",
    "    data = torch.cat((preprocess(Image.open(tile).convert('RGB')).reshape(1,3,pxsize,pxsize), data), axis=0)\n",
    "\n",
    "X_train, X_validation = torch.split(data, int(train_fraction*len(data)))\n",
    "y_train, y_validation = torch.split(torch.Tensor(labels).type(torch.LongTensor), int(train_fraction*len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330c9202-d7f0-468b-a4cc-9701938e0875",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.1+cpu\n",
      "Is CUDA enabled? False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b932b6e-3dff-4cf1-a1c5-4addf4544048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define hyperparamerts of the network and train it\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train, y_train) \n",
    "dataloader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "res50 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "    \n",
    "res50.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 2),\n",
    "               nn.Softmax())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(res50.fc.parameters(), lr=0.0001)\n",
    "res50.to('cuda')\n",
    "epochs = 3\n",
    "\n",
    "run_loss = 0\n",
    "# print start\n",
    "print('Start of training')\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch:', epoch)\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = res50.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss += loss.item()\n",
    "    # print statistics\n",
    "    print('Loss:', run_loss, '\\n')\n",
    "    run_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0002f2e-e774-4f2f-960b-5bb3454b9cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_labels = torch.argmax(net(X_validation), axis=1)\n",
    "print(\"Predicted labels\")\n",
    "print(pred_labels)\n",
    "print(\"True labels\")\n",
    "print(y_validation)\n",
    "\n",
    "C = confusion_matrix(pred_labels, y_validation)\n",
    "print(\"Confusion Matrix\")\n",
    "print(C)\n",
    "print(\"Accuracy: \", (sum(pred_labels==y_validation)/len(pred_labels)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbe231-5ce0-40fc-b71a-a42ad3bcae46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64459b53-7efc-4c42-b6ea-ebd3639d9606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48901957-5316-4bb4-8ee7-968f15283f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8f25e-7f69-4c66-afae-f402fc879891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
